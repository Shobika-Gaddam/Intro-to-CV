{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca737ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220f12c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"chair.jpeg\",1)\n",
    "cv2.line(img,(0,0),(255,255),(0,0,255),10) #bgr - 255 for the color, others are 0\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0a025b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"chair.jpeg\",1)\n",
    "cv2.circle(img,(250,250),20,(0,255,0),-1) #-1 fills in the shape\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb9f0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"chair.jpeg\",1)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "img1=cv2.putText(img,\"Chair\",(200,200),font,2,(200,10,10),5,cv2.LINE_AA)\n",
    "cv2.imshow('image',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2fc890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1f2061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an image\n",
    "img=np.zeros([512,512,3],np.uint8)\n",
    "cv2.putText(img,\"Hello\",(200,200),font,2,(255,255,255),5,cv2.LINE_AA)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff918a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "#identify the coordinates by mouse click\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "events = [i for i in dir(cv2) if 'EVENT' in i]\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce717158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 ,  266\n",
      "273 ,  311\n",
      "329 ,  326\n",
      "412 ,  196\n",
      "327 ,  116\n",
      "217 ,  118\n",
      "121 ,  167\n",
      "105 ,  265\n",
      "105 ,  368\n",
      "483 ,  75\n",
      "251 ,  27\n",
      "131 ,  82\n",
      "61 ,  33\n",
      "23 ,  179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def click_event(event, x, y, flag, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(x, ', ', y)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        strXY = str(x)+ ','+ str(y)\n",
    "        cv2.putText(img,strXY,(x,y), font,0.5,(255,255,0), 2)\n",
    "        cv2.imshow('image',img)\n",
    "        \n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c391b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red:  0\n",
      "Green:  0\n",
      "Blue:  0\n",
      "BRG Format:  [0 0 0]\n",
      "Coordinates of pixel: X:  335 Y:  257\n",
      "Red:  0\n",
      "Green:  0\n",
      "Blue:  0\n",
      "BRG Format:  [0 0 0]\n",
      "Coordinates of pixel: X:  171 Y:  386\n"
     ]
    }
   ],
   "source": [
    "#if Right button is clicked, then rgb values must show\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mouseRGB(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_RBUTTONDOWN: #checks mouse left button down condition\n",
    "        colorsB = img[y,x,0]\n",
    "        colorsG = img[y,x,1]\n",
    "        colorsR = img[y,x,2]\n",
    "        colors = img[y,x]\n",
    "        print(\"Red: \",colorsR)\n",
    "        print(\"Green: \",colorsG)\n",
    "        print(\"Blue: \",colorsB)\n",
    "        print(\"BRG Format: \",colors)\n",
    "        print(\"Coordinates of pixel: X: \",x,\"Y: \",y)\n",
    "sg =cv2.imread(r'chair.jpeg',1) \n",
    "#img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.imshow('image',sg)\n",
    "cv2.setMouseCallback('image',mouseRGB)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c21ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default resolution of webcam\n",
    "import cv2\n",
    "vcap=cv2.VideoCapture(0)\n",
    "print(vcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(vcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e33048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "320.0\n",
      "240.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change original resolution\n",
    "#for width value is 3 and for height it is 4\n",
    "vcap=cv2.VideoCapture(0)\n",
    "print(vcap.set(3,300))\n",
    "print(vcap.set(4,300))\n",
    "print(vcap.get(3))\n",
    "print(vcap.get(4))\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6cc0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "320.0\n",
      "240.0\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcap=cv2.VideoCapture(0)\n",
    "print(vcap.set(3,300))\n",
    "print(vcap.set(4,300))\n",
    "\n",
    "print(vcap.get(3))\n",
    "print(vcap.get(4))\n",
    "\n",
    "print(vcap.isOpened())\n",
    "\n",
    "while(vcap.isOpened()):\n",
    "    ret, frame=vcap.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('Frame',gray)\n",
    "    if cv2.waitKey(10) & 0Xff==ord('q'):        \n",
    "        break\n",
    "#if we increase waitkey, video will get delayed\n",
    "\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e70566ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "960.0\n",
      "540.0\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "vcap=cv2.VideoCapture(0)\n",
    "print(vcap.set(3,1200))\n",
    "print(vcap.set(4,720))\n",
    "\n",
    "print(vcap.get(3))\n",
    "print(vcap.get(4))\n",
    "\n",
    "print(vcap.isOpened())\n",
    "\n",
    "while(vcap.isOpened()):\n",
    "    ret, frame=vcap.read()\n",
    "    if ret == True:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = 'Width'+str(vcap.get(3))+' '+'Height'+str(vcap.get(4))\n",
    "        frame = cv2.putText(frame,text,(10,50),font,1,(100,255,255),1,cv2.LINE_AA)\n",
    "    cv2.imshow('Frame',frame)\n",
    "    if cv2.waitKey(10) & 0Xff==ord('q'):\n",
    "        break\n",
    "        \n",
    "vcap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f86868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "vcap=cv2.VideoCapture(0)\n",
    "print(vcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(vcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#print(vcap.set(3,1200))\n",
    "#print(vcap.set(4,720))\n",
    "\n",
    "#print(vcap.get(3))\n",
    "#print(vcap.get(4))\n",
    "\n",
    "print(vcap.isOpened())\n",
    "\n",
    "while(vcap.isOpened()):\n",
    "    ret, frame=vcap.read()\n",
    "    if ret == True:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        #text = 'Width'+str(vcap.get(3))+' '+'Height'+str(vcap.get(4))\n",
    "        datet=str(datetime.datetime.now())\n",
    "        frame = cv2.putText(frame,datet,(2,50),font,0.5,(0,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0Xff==ord('q'):\n",
    "        break\n",
    "        \n",
    "vcap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b14ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b50c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "\n",
    "while(vcap.isOpened()):\n",
    "    ret, frame=vcap.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow('video',frame)            \n",
    "    if cv2.waitKey(10) & 0Xff ==ord('q'):  \n",
    "        break\n",
    "\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0312a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame=vcap.read()\n",
    "    if not ret:\n",
    "        vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "        continue\n",
    "    \n",
    "    cv2.imshow('video',frame)   \n",
    "    \n",
    "    if cv2.waitKey(10) & 0Xff ==ord('q'):  \n",
    "        break\n",
    "\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846238c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame=vcap.read()\n",
    "    if not ret:\n",
    "        vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "        continue\n",
    "    \n",
    "        hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "        low_yellow=np.array([18,94,120])\n",
    "        high_yellow=np.array([48,255,255])\n",
    "        mask = cv2.inRange(hsv, low_yellow, high_yellow)\n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0Xff ==ord('q'):  \n",
    "        break\n",
    "\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74b769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame=vcap.read()    \n",
    "    if not ret:\n",
    "        vcap = cv2.VideoCapture(r\"C:\\Users\\shobi\\OneDrive\\Desktop\\Woxsen\\Term 3\\ML for Computer Vision\\road_view.mp4\")\n",
    "        continue\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    low_yellow=np.array([18,94,120])\n",
    "    high_yellow=np.array([48,255,255])\n",
    "    mask = cv2.inRange(hsv, low_yellow, high_yellow)\n",
    "    edges = cv2.Canny(mask, 100, 200)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)       #rho=1, teeta=np.pi/180, \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0,255,0), 5)\n",
    "    \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Edges\", edges)\n",
    "\n",
    "    if cv2.waitKey(10) & 0Xff ==ord('q'):  \n",
    "        break\n",
    "\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1f158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26176b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(r'lena.png', 1)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img_blur = cv2.GaussianBlur(img_gray, (7,7), 10) #image name, kernel matrix, sigma value - to change the blur\n",
    "img_edges = cv2.Canny(img, 150, 200)\n",
    "img_dilation = cv2.dilate(img_edges, kernel, 1) #iterations\n",
    "img_erosion = cv2.erode(img_dilation, kernel, 1)\n",
    "\n",
    "cv2.imshow(\"Gray\",img_gray)\n",
    "cv2.imshow(\"Blur\",img_blur)\n",
    "cv2.imshow(\"Edges\",img_edges)\n",
    "cv2.imshow(\"Dilation\",img_dilation)\n",
    "cv2.imshow(\"Erosion\",img_erosion)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7092164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformation\n",
    "\n",
    "#cv2.getPerspectiveTransform method \n",
    "#Syntax: cv2.getPerspectiveTransform(src, dst) \n",
    "#Parameters: \n",
    "#src: Coordinates of quadrangle vertices in the source image.\n",
    "#dst: Coordinates of the corresponding quadrangle vertices in the destination image.\n",
    "\n",
    "#cv2.wrapPerspective method \n",
    "#Syntax: cv2.warpPerspective(src, dst, dsize)\n",
    "#Parameters: \n",
    "#src: Source Image\n",
    "#dst: output image that has the size dsize and the same type as src.\n",
    "#dsize: size of output image\n",
    "\n",
    "#https://www.geeksforgeeks.org/perspective-transformation-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf29ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Turn on Laptop's webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "     \n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # Locate points of the documents or object which you want to transform\n",
    "    pts1 = np.float32([[0, 260], [640, 260],\n",
    "                       [0, 400], [640, 400]])\n",
    "    pts2 = np.float32([[0, 0], [400, 0],\n",
    "                       [0, 640], [400, 640]])\n",
    "     \n",
    "    # Apply Perspective Transform Algorithm\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    result = cv2.warpPerspective(frame, matrix, (500, 600))\n",
    "     \n",
    "    # Wrap the transformed image\n",
    "    cv2.imshow('frame', frame) # Initial Capture\n",
    "    cv2.imshow('frame1', result) # Transformed Capture\n",
    " \n",
    "    if cv2.waitKey(24) & 0Xff ==ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b132f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(r'cards.png', 1)\n",
    "\n",
    "while True:\n",
    "     \n",
    "    pts1 = np.float32([[0, 260], [640, 260],\n",
    "                       [0, 400], [640, 400]])\n",
    "    pts2 = np.float32([[0, 0], [400, 0],\n",
    "                       [0, 640], [400, 640]])\n",
    "     \n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    result = cv2.warpPerspective(img, matrix, (500, 600))\n",
    "     \n",
    "    cv2.imshow('image', img) \n",
    "    cv2.imshow('frame1', result) \n",
    " \n",
    "    if cv2.waitKey(0) & 0Xff ==ord('q'):\n",
    "        break\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd5ecdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 704, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(r'cards.png', 1)\n",
    "img.shape\n",
    "#width,height = 700,430 #x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5642168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 ,  33\n",
      "667 ,  8\n",
      "7 ,  247\n",
      "538 ,  252\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(r'cards.png', 1)\n",
    "\n",
    "def click_event(event, x, y, flag, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(x, ', ', y)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        strXY = str(x)+ ','+ str(y)\n",
    "        cv2.putText(img,strXY,(x,y), font,0.5,(255,255,0), 2)\n",
    "        \n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d609aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    pts1 = np.float32([[163 ,  33], [670 ,  6],\n",
    "                       [10 ,  252], [540 ,  256]])\n",
    "    pts2 = np.float32([[0, 0], [700, 0],\n",
    "                       [0, 430], [700, 430]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    result = cv2.warpPerspective(img, matrix, (700, 430))\n",
    "     \n",
    "    cv2.imshow('image', img) \n",
    "    cv2.imshow('frame1', result) \n",
    " \n",
    "    if cv2.waitKey(0) & 0Xff ==ord('q'):\n",
    "        break\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5334fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
